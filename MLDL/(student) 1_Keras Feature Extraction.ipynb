{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Keras Start\n",
    "\n",
    "- 1.4 Simple CNN\n",
    "- 1.5 BatchNormalization & Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Simple CNN\n",
    "이번 실습은 classifier 역할을 하는 DNN 앞에, feature extractor 역할을 하는 Covolution layer를 및 Maxplling layer를 덧붙여\n",
    "\n",
    "CNN 모델을 만들고 학습시켜 볼 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datasets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m (X_train, Y_train),(X_test, Y_test) \u001b[38;5;241m=\u001b[39m \u001b[43mdatasets\u001b[49m\u001b[38;5;241m.\u001b[39mmnist\u001b[38;5;241m.\u001b[39mload_data()\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_train\u001b[38;5;241m.\u001b[39mshape, Y_train\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'datasets' is not defined"
     ]
    }
   ],
   "source": [
    "(X_train, Y_train),(X_test, Y_test) = datasets.mnist.load_data()\n",
    "print(X_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST 데이터는 load했을 때 channel이 없기 때문에 channel을 추가하여 3차원 이미지로 바꿔주어야 함(batch차원 제외)\n",
    "\n",
    "Tensorflow base에서는 (batch, image row, image column, image channel)으로 이미지를 학습\n",
    "\n",
    "Teano base에서는 (batch, image channel, image row, image column)으로 이미지를 학습\n",
    "\n",
    "backend.image_data_format()로 channel의 위치를 확인하고 reshape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend\n",
    "backend.image_data_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
    "\n",
    "Y_train = utils.to_categorical(Y_train)\n",
    "Y_test = utils.to_categorical(Y_test)\n",
    "\n",
    "print(X_train.shape, Y_train.shape)\n",
    "\n",
    "n_in = X_train.shape[1:]\n",
    "n_out = Y_train.shape[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<사용되는 Layer>\n",
    "\n",
    "`Conv2D` : 이미지에 필터의 파라미터를 convolution 연산하여 다음 layer로 전달\n",
    "\n",
    "https://keras.io/layers/convolutional/#conv2d\n",
    "\n",
    "`MaxPooling2D` : 필터에 겹치는 값들 중 가장 큰 값만 다음 layer로 전달\n",
    "\n",
    "https://keras.io/layers/pooling/#maxpooling2d\n",
    "\n",
    "`Flatten` : 다차원 tensor를 1차원 벡터로 변환\n",
    "\n",
    "https://keras.io/layers/core/#flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Flatten, BatchNormalization, Dropout, ReLU\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CNN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 12\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# model = DNN_seq(n_in, n_out)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m model\u001b[38;5;241m=\u001b[39m\u001b[43mCNN\u001b[49m(n_in, n_out)\n\u001b[1;32m     13\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_model\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CNN' is not defined"
     ]
    }
   ],
   "source": [
    "def DNN_seq(n_in, n_out):\n",
    "    # Coding Time (5 min) layer : 784 → 128 → 32 → 10, acitvation : relu → relu → softmax\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 128, input_shape = (n_in,), activation = 'relu'))    # Dense : FClayer\n",
    "    model.add(Dense(units = 32, input_shape = (128,), activation = 'relu'))\n",
    "    model.add(Dense(units = 10, input_shape = (32,), activation = 'softmax'))\n",
    "    return model\n",
    "\n",
    "# model = DNN_seq(n_in, n_out)\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model=CNN(n_in, n_out)\n",
    "model.summary()\n",
    "\n",
    "from tensorflow.keras.utils import plot_model\n",
    "%matplotlib inline\n",
    "plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) 모델의 학습과정 설정\n",
    "\n",
    "optimizer에 문자열 대신에 파라미터를 수정한 optimizer를 입력할 수 있음\n",
    "\n",
    "https://keras.io/optimizers/#adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "adam = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, decay=1e-6, epsilon=None, amsgrad=False)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) 모델 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Coding Time\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (5) 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_and_accuracy = model.evaluate(X_test, Y_test, batch_size=128)\n",
    "print('loss : %.4f, accruracy : %.4f'%(loss_and_accuracy[0],loss_and_accuracy[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 BatchNormalization & DropOut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<사용되는 Layer>\n",
    "\n",
    "`Dropout` : 일부 뉴런을 drop하여 overfitting을 방지\n",
    "\n",
    "https://keras.io/layers/core/#dropout\n",
    "    \n",
    "보통 batchnormalization, dropout은 동시에 사용하지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_Dropout(n_in, n_out):\n",
    "    # Feature Extraction\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, kernel_size=(3, 3), padding='same', input_shape=n_in))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "    model.add(Conv2D(32, (3, 3), padding='same',strides=(2, 2)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "    \n",
    "    # Classifier\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "    model.add(Dense(n_out, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "def CNN_Dropout_func(n_in, n_out):\n",
    "    input = Input(shape=(n_in))\n",
    "    x = Conv2D(16, kernel_size=(3, 3), padding='same', input_shape=n_in)(input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(32, kernel_size=(3, 3), padding='same', input_shape=n_in)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(128)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dense(n_out)(x)\n",
    "    y = Activation('softmax')(x)\n",
    "    model = Model(inputs = input, outputs = y)\n",
    "    return model\n",
    "\n",
    "model=CNN_Dropout_func(n_in, n_out)\n",
    "model.summary()\n",
    "\n",
    "from tensorflow.keras.utils import plot_model\n",
    "%matplotlib inline\n",
    "plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## (3) 모델의 학습과정 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, decay=1e-6, epsilon=None, amsgrad=False)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) 모델 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "earlystopper = EarlyStopping(monitor='val_accuracy', patience=7, verbose=0, mode='auto')\n",
    "history = model.fit(X_train, Y_train, batch_size=128, epochs=30, validation_split=0.2, callbacks = [earlystopper])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (5) 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_and_accuracy = model.evaluate(X_test, Y_test, batch_size=128)\n",
    "print('loss : %.4f, accruracy : %.4f'%(loss_and_accuracy[0],loss_and_accuracy[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (6) 모델 저장하고 불러오기\n",
    "\n",
    "저장하기 : model 객체의 내부 함수인 save() .h5 형식으로 저장할 수 있음 [1.모델의 구조, 2.학습된 파라미터, 3.complie() 설정]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coding Time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "불러오기 : load_model 함수로 .h5 파일에서 모델을 불러올 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coding Time\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
