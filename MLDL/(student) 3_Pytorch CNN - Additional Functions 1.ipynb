{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9a48bc1",
   "metadata": {},
   "source": [
    "# í•™ìŠµ ë‚´ìš©\n",
    " - 3.1 Pytorch CIFAR10 - CNN(ìƒˆë¡œìš´ ë°ì´í„°ì…‹ì¸ CIFAR-10ê³¼ ë°ì´í„° ì¦ê°•(Data Augmentation)ì— ëŒ€í•˜ì—¬ ë°°ìš´ë‹¤\n",
    " - 3.2 Fine Tuning with Custom Dataset(ì‚¬ëŒê³¼ ì›ìˆ­ì´ ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµì‹œí‚¤ê¸°)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d16585e",
   "metadata": {},
   "source": [
    "# 3.1 Pytorch CIFAR-10 - CNN\n",
    " - CNNì„ ì´ìš©í•˜ì—¬ ìƒˆë¡œìš´ ë°ì´í„°ì…‹ì¸ CIFAR-10ì„ ë¶„ë¥˜í•˜ëŠ” ëª¨ë¸ì„ ë§Œë“¤ì–´ë³¸ë‹¤\n",
    " - ë°ì´í„° ì¦ê°•(Data Augmentation) ê¸°ë²•ì„ ì´ìš©í•´ë³¸ë‹¤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e81132",
   "metadata": {},
   "source": [
    "## 3.1.1 PyTorch GPU êµ¬ë™ ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸í•˜ê¸°\n",
    "- Pytorchë¥¼ GPUë¡œ êµ¬ë™í• ìˆ˜ ìˆëŠ” ì¡°ê±´ì¸ì§€ë¥¼ í™•ì¸í•œë‹¤\n",
    "- ê²°ê³¼ê°€ CPUë¡œ ë‚˜ì˜¤ë©´, ê°€ìƒí™˜ê²½ì„ ì§€ìš°ê³  ë‹¤ì‹œ ê¹”ì•„ì•¼ í•œë‹¤ (Pytorch, Keras ê°€ìƒí™˜ê²½ ë§Œë“œëŠ”ë²•.pptx ì°¸ì¡°)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e2ccf6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU ì‚¬ìš© ë¶ˆê°€ëŠ¥ ìƒíƒœ\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available() == True:\n",
    "    device = 'cuda:0'\n",
    "    print('í˜„ì¬ ê°€ìƒí™˜ê²½ GPU ì‚¬ìš© ê°€ëŠ¥ìƒíƒœ')\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print('GPU ì‚¬ìš© ë¶ˆê°€ëŠ¥ ìƒíƒœ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ab152f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# êµìœ¡ í™˜ê²½ì—ì„œì˜ ì‹œë“œ ê³ ì •\n",
    "def seed(seed = 1234):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed() # ì‹œë“œ ê³ ì •"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e9223b",
   "metadata": {},
   "source": [
    "## 3.1.2 í•˜ì´í¼ íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    " - ëª¨ë¸ êµ¬ë™ì— í•„ìš”í•œ í•˜ì´í¼ íŒŒë¼ë¯¸í„°ë“¤ì„ ì„¤ì •í•œë‹¤\n",
    " - í•˜ì´í¼ íŒŒë¼ë¯¸í„° ì„¤ì •ê°’ì— ë”°ë¼ì„œ ëª¨ë¸ì˜ êµ¬ë™ ì†ë„, ì •í™•ë„, í•™ìŠµ ì†ë„ê°€ ë‹¬ë¼ì§„ë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03e90cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "maximum_epoch = 15\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e9b3bd",
   "metadata": {},
   "source": [
    "## 3.1.3 ë°ì´í„° ë¡œë“œ & ì „ì²˜ë¦¬\n",
    " - CIFAR-10 ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œ ë°›ëŠ”ë‹¤\n",
    " - Train, Validation, Test ë°ì´í„°ë¥¼ ë¶„í• í•´ì¤€ë‹¤\n",
    " - ì‹¤ìŠµ ì‹œê°„ì„ ê³ ë ¤í•˜ì—¬ ì „ì²´ ë°ì´í„°ì˜ ì ˆë°˜ë§Œ í•™ìŠµí•˜ëŠ”ë° ì‚¬ìš©í•˜ë„ë¡ í•œë‹¤\n",
    " - ì´ë¯¸ì§€ë¥¼ 56 * 56ìœ¼ë¡œ Resizeì‹œí‚¨ë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2730af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed() # ì‹œë“œ ê³ ì •\n",
    "# Load dataset into python variable\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToTensor, Resize, Normalize, RandomHorizontalFlip, RandomCrop\n",
    "import numpy as np\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "input_transform = transforms.Compose([ToTensor(), Resize(56), RandomCrop(56, padding = 6), \n",
    "                                      RandomHorizontalFlip(), Normalize(mean, std)])\n",
    "\n",
    "test_transform = transforms.Compose([ToTensor(), Resize(56), Normalize(mean, std)])\n",
    "\n",
    "transform_for_show = transforms.Compose([ToTensor(), Resize(512)])\n",
    "\n",
    "# ì½”ë”©íƒ€ì„(CIFAR10 ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ) - 1ë¶„\n",
    "\n",
    "\n",
    "##########\n",
    "\n",
    "from torch.utils.data import random_split\n",
    "train_data, valid_data, _ = random_split(train_data, [20000, 3000, 27000])\n",
    "test_data = CIFAR10(\"./\", train=False, transform=test_transform, download=True)\n",
    "\n",
    "show_data = CIFAR10(\"./\", train=True, transform=transform_for_show, download=True)\n",
    "\n",
    "# Check the data\n",
    "print('Train ê¸¸ì´: {}'.format(len(train_data)))\n",
    "print('Valid ê¸¸ì´: {}'.format(len(valid_data)))\n",
    "print('Test  ê¸¸ì´: {}'.format(len(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c38236",
   "metadata": {},
   "source": [
    "- Train / Validation / Test ë°ì´í„°ê°€ ì œëŒ€ë¡œ ë‚˜ë‰˜ì—ˆëŠ”ì§€ ê¸¸ì´ë¥¼ í™•ì¸\n",
    "- ë°ì´í„°ë¥¼ ì‹œê°í™”í•˜ì—¬ í™•ì¸í•œë‹¤\n",
    "- ë¹„í–‰ê¸°, ìë™ì°¨, ìƒˆ, ê³ ì–‘ì´, ì‚¬ìŠ´, ê°œ, ê°œêµ¬ë¦¬, ë§, ë°°, íŠ¸ëŸ­ ì´ 10ê°€ì§€ classë¡œ ì´ë£¨ì–´ì§„ ë°ì´í„°ì…‹ì´ë‹¤\n",
    "- ê° ë°ì´í„°ë§ˆë‹¤ ë¼ë²¨ì´ ì¡´ì¬í•œë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef95ec5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('ëª¨ë“  Class ì¶œë ¥: {}\\n'.format(test_data.classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f8326d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ëª¨ë“  Classì— í•´ë‹¹í•˜ëŠ” ì‚¬ì§„ í™•ì¸\n",
    "seed() # ì‹œë“œ ê³ ì •\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "cnt = 0\n",
    "for img, label in show_data:\n",
    "    if cnt == 10:\n",
    "        break\n",
    "    if label == cnt:\n",
    "        cnt += 1\n",
    "        img = torchvision.utils.make_grid(img)\n",
    "        npimg = img.numpy()\n",
    "        plt.title('Label: {}'.format(test_data.classes[label]))\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e25751",
   "metadata": {},
   "source": [
    "### ë°ì´í„° ë¡œë” ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a3ce46",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed() # ì‹œë“œ ê³ ì •\n",
    "# Create data loader\n",
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, pin_memory=True, drop_last=True)\n",
    "valid_loader = DataLoader(valid_data, batch_size=batch_size, pin_memory=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d6ef9f",
   "metadata": {},
   "source": [
    "## 3.1.4 í•™ìŠµì— í•„ìš”í•œ ê¸°ëŠ¥ ì œì‘\n",
    "- ëª¨ë¸ í•™ìŠµì— í•„ìš”í•œ ê¸°ëŠ¥ë“¤(í•™ìŠµ, ì‹œê°í™”, ê²°ê³¼ ë¶„ì„)ë“±ì„ ìœ„í•´ í•„ìš”í•œ ê¸°ëŠ¥ë“¤ì„ ì„ ì–¸í•œë‹¤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54c8af9",
   "metadata": {},
   "source": [
    "## 3.1.5 ëª¨ë¸ ì„ ì–¸í›„ í•™ìŠµ - CNN with Data Augmentation(VGG11 ë”°ë¼í•˜ê¸°)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c62261",
   "metadata": {},
   "source": [
    "### ëª¨ë¸ ì„ ì–¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2758ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Model\n",
    "from torch.optim import Adam\n",
    "def init_model():\n",
    "    global net, loss_fn, optim\n",
    "    net = CNN_Model().to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optim = Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "class CNN_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_Model, self).__init__()\n",
    "        \n",
    "        # ì½”ë”©íƒ€ì„\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        ##########\n",
    "    \n",
    "    def forward(self, data):\n",
    "        conv_out = self.convolution_part(data)\n",
    "        avg_out = self.channelavg_part(conv_out)\n",
    "        avg_out_flatten = avg_out.reshape(avg_out.size(0), -1)\n",
    "        classifier_out = self.classifier_part(avg_out_flatten)\n",
    "        return classifier_out, conv_out\n",
    "\n",
    "from torchsummary import summary as Summary\n",
    "# Model structure check\n",
    "Summary(CNN_Model().to(device), (3, 56, 56))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da77e728",
   "metadata": {},
   "source": [
    "## í•™ìŠµì— ì‚¬ìš©ë˜ëŠ” í•¨ìˆ˜\n",
    " - ì´ˆê¸°í™”\n",
    " - ëª¨ë¸ êµ¬ë™\n",
    " - í•™ìŠµ ì¶”ì´"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995fded9",
   "metadata": {},
   "source": [
    "### ì´ˆê¸°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00409750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ ì´ˆê¸°í™”\n",
    "from torch.optim import Adam\n",
    "def init_model():\n",
    "    plt.rc('font', size = 10)\n",
    "    global net, loss_fn, optim\n",
    "    net = CNN_Model().to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optim = Adam(net.parameters(), lr=learning_rate)\n",
    "    \n",
    "# epoch ì¹´ìš´í„° ì´ˆê¸°í™”\n",
    "def init_epoch():\n",
    "    global epoch_cnt\n",
    "    epoch_cnt = 0\n",
    "\n",
    "def init_log():\n",
    "    plt.rc('font', size = 10)\n",
    "    # ëª¨ë“  Logë¥¼ ì´ˆê¸°í™”\n",
    "    global log_stack, iter_log, tloss_log, tacc_log, vloss_log, vacc_log, time_log\n",
    "    iter_log, tloss_log, tacc_log, vloss_log, vacc_log = [], [], [], [], []\n",
    "    time_log, log_stack = [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2ad05a",
   "metadata": {},
   "source": [
    "### ëª¨ë¸ êµ¬ë™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ef4028",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from torch.cuda import memory_allocated, empty_cache\n",
    "def clear_memory():\n",
    "    if device != 'cpu':\n",
    "        empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "# í•™ìŠµ ì•Œê³ ë¦¬ì¦˜\n",
    "import numpy as np\n",
    "def epoch(data_loader, mode = 'train'):\n",
    "    global epoch_cnt\n",
    "    \n",
    "    # ì‚¬ìš©ë˜ëŠ” ë³€ìˆ˜ ì´ˆê¸°í™”\n",
    "    iter_loss, iter_acc, last_grad_performed  = [], [], False\n",
    "    \n",
    "    # 1 iteration í•™ìŠµ ì•Œê³ ë¦¬ì¦˜(forë¬¸ì„ ë‚˜ì˜¤ë©´ 1 epoch ì™„ë£Œ)\n",
    "    for _data, _label in data_loader:\n",
    "        data, label = _data.to(device), _label.to(device)\n",
    "        \n",
    "        # 1. Feed-forward\n",
    "        if mode == 'train':\n",
    "            net.train()\n",
    "        else:\n",
    "            # í•™ìŠµë•Œë§Œ ì“°ì´ëŠ” Dropout, Batch Mormalizationì„ ë¯¸ì‚¬ìš©\n",
    "            net.eval()\n",
    "\n",
    "        result, _ = net(data) # 1 Batchì— ëŒ€í•œ ê²°ê³¼ê°€ ëª¨ë“  Classì— ëŒ€í•œ í™•ë¥ ê°’ìœ¼ë¡œ\n",
    "        _, out = torch.max(result, 1) # resultì—ì„œ ìµœëŒ€ í™•ë¥ ê°’ì„ ê¸°ì¤€ìœ¼ë¡œ ì˜ˆì¸¡ class ë„ì¶œ\n",
    "        \n",
    "        # 2. Loss ê³„ì‚°\n",
    "        loss = loss_fn(result, label) # GT ì™€ Label ë¹„êµí•˜ì—¬ Loss ì‚°ì •\n",
    "        iter_loss.append(loss.item()) # í•™ìŠµ ì¶”ì´ë¥¼ ìœ„í•˜ì—¬ Lossë¥¼ ê¸°ë¡\n",
    "        \n",
    "        # 3. ì—­ì „íŒŒ í•™ìŠµ í›„ Gradient Descent\n",
    "        if mode == 'train':\n",
    "            optim.zero_grad() # ë¯¸ë¶„ì„ í†µí•´ ì–»ì€ ê¸°ìš¸ê¸° ì´ˆê¸°í™” for ë‹¤ìŒ epoch\n",
    "            loss.backward() # ì—­ì „íŒŒ í•™ìŠµ\n",
    "            optim.step() # Gradient Descent ìˆ˜í–‰\n",
    "            last_grad_performed = True # forë¬¸ ë‚˜ê°€ë©´ epoch ì¹´ìš´í„° += 1\n",
    "            \n",
    "        # 4. ì •í™•ë„ ê³„ì‚°\n",
    "        acc_partial = (out == label).float().sum() # GT == Label ì¸ ê°œìˆ˜\n",
    "        acc_partial = acc_partial / len(label) # ( TP / (TP + FP)) í•´ì„œ ì •í™•ë„ ì‚°ì¶œ\n",
    "        iter_acc.append(acc_partial.item()) # í•™ìŠµ ì¶”ì´ë¥¼ ìœ„í•˜ì—¬ Acc. ê¸°ë¡\n",
    "\n",
    "    # ì—­ì „íŒŒ í•™ìŠµ í›„ Epoch ì¹´ìš´í„° += 1\n",
    "    if last_grad_performed:\n",
    "        epoch_cnt += 1\n",
    "    \n",
    "    clear_memory()\n",
    "    \n",
    "    # lossì™€ accì˜ í‰ê· ê°’ for í•™ìŠµì¶”ì´ ê·¸ë˜í”„\n",
    "    return np.average(iter_loss), np.average(iter_acc)\n",
    "\n",
    "def epoch_not_finished():\n",
    "    # ì—í­ì´ ëë‚¨ì„ ì•Œë¦¼\n",
    "    return epoch_cnt < maximum_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f172a7",
   "metadata": {},
   "source": [
    "### í•™ìŠµ ì¶”ì´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bc29fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_train_log(_tloss, _tacc, _time):\n",
    "    # Train Log ê¸°ë¡ìš©\n",
    "    time_log.append(_time)\n",
    "    tloss_log.append(_tloss)\n",
    "    tacc_log.append(_tacc)\n",
    "    iter_log.append(epoch_cnt)\n",
    "    \n",
    "def record_valid_log(_vloss, _vacc):\n",
    "    # Validation Log ê¸°ë¡ìš©\n",
    "    vloss_log.append(_vloss)\n",
    "    vacc_log.append(_vacc)\n",
    "\n",
    "def last(log_list):\n",
    "    # ë¦¬ìŠ¤íŠ¸ ì•ˆì˜ ë§ˆì§€ë§‰ ìˆ«ìë¥¼ ë°˜í™˜(print_log í•¨ìˆ˜ì—ì„œ ì‚¬ìš©)\n",
    "    if len(log_list) > 0:\n",
    "        return log_list[len(log_list) - 1]\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "from IPython.display import clear_output\n",
    "def print_log():\n",
    "    # í•™ìŠµ ì¶”ì´ ì¶œë ¥\n",
    "\n",
    "    # ì†Œìˆ«ì  3ìë¦¬ ìˆ˜ê¹Œì§€ ì¡°ì ˆ\n",
    "    train_loss = round(float(last(tloss_log)), 3)\n",
    "    train_acc = round(float(last(tacc_log)), 3)\n",
    "    val_loss = round(float(last(vloss_log)), 3)\n",
    "    val_acc = round(float(last(vacc_log)), 3)\n",
    "    time_spent = round(float(last(time_log)), 3)\n",
    "    \n",
    "    log_str = 'Epoch: {:3} | T_Loss {:5} | T_acc {:5} | V_Loss {:5} | V_acc. {:5} | \\\n",
    "ğŸ•’ {:5}'.format(last(iter_log), train_loss, train_acc, val_loss, val_acc, time_spent)\n",
    "    \n",
    "    log_stack.append(log_str) # í”„ë¦°íŠ¸ ì¤€ë¹„\n",
    "    \n",
    "    # í•™ìŠµ ì¶”ì´ ê·¸ë˜í”„ ì¶œë ¥\n",
    "    hist_fig, loss_axis = plt.subplots(figsize=(10, 3), dpi=99) # ê·¸ë˜í”„ ì‚¬ì´ì¦ˆ ì„¤ì •\n",
    "    hist_fig.patch.set_facecolor('white') # ê·¸ë˜í”„ ë°°ê²½ìƒ‰ ì„¤ì •\n",
    "    \n",
    "    # Loss Line êµ¬ì„±\n",
    "    loss_t_line = plt.plot(iter_log, tloss_log, label='Train Loss', color='red', marker='o')\n",
    "    loss_v_line = plt.plot(iter_log, vloss_log, label='Valid Loss', color='blue', marker='s')\n",
    "    loss_axis.set_xlabel('epoch')\n",
    "    loss_axis.set_ylabel('loss')\n",
    "    \n",
    "    # Acc. Line êµ¬ì„±\n",
    "    acc_axis = loss_axis.twinx()\n",
    "    acc_t_line = acc_axis.plot(iter_log, tacc_log, label='Train Acc.', color='red', marker='+')\n",
    "    acc_v_line = acc_axis.plot(iter_log, vacc_log, label='Valid Acc.', color='blue', marker='x')\n",
    "    acc_axis.set_ylabel('accuracy')\n",
    "    \n",
    "    # ê·¸ë˜í”„ ì¶œë ¥\n",
    "    hist_lines = loss_t_line + loss_v_line + acc_t_line + acc_v_line # ìœ„ì—ì„œ ì„ ì–¸í•œ pltì •ë³´ë“¤ í†µí•©\n",
    "    loss_axis.legend(hist_lines, [l.get_label() for l in hist_lines], loc = 'upper right') # ìˆœì„œëŒ€ë¡œ ê·¸ë ¤ì£¼ê¸°\n",
    "    loss_axis.grid() # ê²©ì ì„¤ì •\n",
    "    plt.title('Learning history until epoch {}'.format(last(iter_log)))\n",
    "    plt.draw()\n",
    "    \n",
    "    # í…ìŠ¤íŠ¸ ë¡œê·¸ ì¶œë ¥\n",
    "    clear_output(wait=True)\n",
    "    plt.show()\n",
    "    for idx in reversed(range(len(log_stack))): # ë°˜ëŒ€ë¡œ sort ì‹œì¼œì„œ ì¶œë ¥\n",
    "        print(log_stack[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1430e46a",
   "metadata": {},
   "source": [
    "### ëª¨ë¸ í•™ìŠµ í›„ ëª¨ë¸ì˜ ì •í™•ë„ ì¶œë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adff80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed() # ì‹œë“œ ê³ ì •\n",
    "# Training Initialization\n",
    "init_model()\n",
    "init_epoch()\n",
    "init_log()\n",
    "\n",
    "# Training Iteration\n",
    "import time\n",
    "while epoch_not_finished():\n",
    "    start_time = time.time()\n",
    "    tloss, tacc = epoch(train_loader, mode = 'train')\n",
    "    end_time = time.time()\n",
    "    time_taken = end_time - start_time\n",
    "    record_train_log(tloss, tacc, time_taken)\n",
    "    with torch.no_grad():\n",
    "        vloss, vacc = epoch(valid_loader, mode = 'val')\n",
    "        record_valid_log(vloss, vacc)\n",
    "    print_log()\n",
    "\n",
    "print('\\n Training completed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35cccfe",
   "metadata": {},
   "source": [
    "### ëª¨ë¸ì˜ ì •í™•ë„ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e61c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •í™•ë„ ê²€ì¦\n",
    "with torch.no_grad():\n",
    "    test_loss, test_acc = epoch(test_loader, mode = 'test')\n",
    "    test_acc = round(test_acc, 4)\n",
    "    test_loss = round(test_loss, 4)\n",
    "    print('Test Acc.: {}'.format(test_acc))\n",
    "    print('Test Loss: {}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f180d6ea",
   "metadata": {},
   "source": [
    "# ============================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5891a85a",
   "metadata": {},
   "source": [
    " - 3.1 CNN - CIFAR 10\n",
    " - 3.2 Transfer Learning   <---\n",
    " - 3.3 GAN with MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb8a8d2",
   "metadata": {},
   "source": [
    "# 3.2 Transfer Learning with Custom Dataset\n",
    " - ì»¤ìŠ¤í…œ ë°ì´í„°ì…‹ì„ ì´ìš©í•˜ì—¬ Fine tuningì„ ìµíŒë‹¤(ResNet18)\n",
    " - ResNet18ì— ì‚¬ëŒê³¼ ì›ìˆ­ì´ë¥¼ í•™ìŠµí•˜ì—¬ ë¶„ë¥˜ ëª¨ë¸ì„ ì œì‘í•´ë³¸ë‹¤\n",
    " - Test Datasetì„ ì§ì ‘ êµ¬í•˜ì—¬, ëª¨ë¸ì´ íš¨ê³¼ì ìœ¼ë¡œ ì‚¬ëŒê³¼ ì›ìˆ­ì´ë¥¼ ë¶„ë¥˜í•˜ëŠ”ì§€ ì‹¤í—˜í•´ë³¸ë‹¤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7286c854",
   "metadata": {},
   "source": [
    "## 3.2.1 Train ë°ì´í„° ë¡œë“œ & ì „ì²˜ë¦¬\n",
    " - í•™ìŠµí•  ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ì˜ í˜•ì‹ì„ ì§€ì •í•´ì¤€ë‹¤\n",
    " - ì»¤ìŠ¤í…œ ë°ì´í„°ì…‹ ì´ë¯¸ì§€ë“¤ì˜ í´ë” ê²½ë¡œë¥¼ ì§€ì •í•œë‹¤\n",
    " - ì´ë¯¸ì§€ì˜ ì‚¬ì´ì¦ˆë¥¼ 224 * 224ë¡œ ë¦¬ì‚¬ì´ì¦ˆ í•´ì¤€ë‹¤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec9eb80",
   "metadata": {},
   "source": [
    "### Split Folderë¡œ Train ë°ì´í„° ìë™ ë¶„í• í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531f3d99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import splitfolders\n",
    "input_folder = './data_day3/dataset_ManAndMonkey_small'\n",
    "output = './data_day3/split_folders_small'\n",
    "\n",
    "# ì½”ë”©íƒ€ì„(split foldersë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ë¶„í• í•˜ê¸°)\n",
    "\n",
    "\n",
    "\n",
    "##########"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce02724",
   "metadata": {},
   "source": [
    "### Train ë°ì´í„° Classë§ˆë‹¤ 5ì¥ì”© ì¶œë ¥í•´ë³´ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6b07cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "data_dir = './data_day3/split_folders_small'\n",
    "train_dir = '{}/train'.format(data_dir)\n",
    "train_folder_list = os.listdir(train_dir)\n",
    " \n",
    "all_imgs = []\n",
    "cnt, cnt_goal = 0, 5\n",
    "num_man, num_monkey = 0, 0\n",
    "\n",
    "import cv2\n",
    "for folder in train_folder_list:\n",
    "    img_name_list = os.listdir('{}/{}'.format(train_dir, folder))\n",
    "    cnt = 0\n",
    "    if 'man' in folder:\n",
    "        num_man = len(img_name_list)\n",
    "    elif 'monkey' in folder:\n",
    "        num_monkey = len(img_name_list)\n",
    "    for img_name in img_name_list:\n",
    "        if cnt_goal == cnt:\n",
    "            break\n",
    "        img_dir = '{}/{}/{}'.format(train_dir, folder, img_name)\n",
    "        img = cv2.imread(img_dir)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        plt.imshow(img)\n",
    "        plt.title('Train: {}'.format(folder))\n",
    "        plt.show()\n",
    "        cnt += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3dd530",
   "metadata": {},
   "source": [
    "### Train ë°ì´í„°ì˜ ê°œìˆ˜ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5437862",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train ì‚¬ëŒì‚¬ì§„: {}ê°œ'.format(num_man))\n",
    "print('Train ì›ìˆ­ì´ ì‚¬ì§„: {}ê°œ'.format(num_monkey))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befb6cf0",
   "metadata": {},
   "source": [
    "### Train ë°ì´í„° transforms.Composeë¡œ ì „ì²˜ë¦¬ ì˜µì…˜ ì ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3eb88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "data_transforms_train = transforms.Compose([ToTensor(), Resize((224,224)), RandomHorizontalFlip(), Normalize(mean, std)])\n",
    "data_transforms_val = transforms.Compose([ToTensor(), Resize((224,224)), Normalize(mean, std)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1849b6a2",
   "metadata": {},
   "source": [
    "### Train ë°ì´í„° ë¡œë”ì— ì‚¬ì§„ ì—…ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9505bbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inport data\n",
    "from torchvision import datasets\n",
    "train_data = datasets.ImageFolder(os.path.join(data_dir, 'train'), data_transforms_train)\n",
    "val_data = datasets.ImageFolder(os.path.join(data_dir, 'val'), data_transforms_val)\n",
    "\n",
    "dataloader_train = torch.utils.data.DataLoader(train_data, batch_size = 10, shuffle = True)\n",
    "dataloader_val = torch.utils.data.DataLoader(val_data, batch_size = len(val_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b032f0f",
   "metadata": {},
   "source": [
    "## 3.2.2 ëª¨ë¸ ì„ ì–¸í›„ í•™ìŠµ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578c3694",
   "metadata": {},
   "source": [
    "### ëª¨ë¸ í•™ìŠµ ì•Œê³ ë¦¬ì¦˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a7e887",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_resnet(net, data_loader, loss_fn, optim, scheduler, mode = 'train'):\n",
    "    global epoch_cnt\n",
    "    iter_loss, iter_acc, last_grad_performed = [], [], False\n",
    "\n",
    "    for _data, _label in data_loader:\n",
    "        data, label = _data.to(device), _label.to(device)\n",
    "        \n",
    "        # 1. Feed-forward\n",
    "        if mode == 'train':\n",
    "            net.train()\n",
    "            grad_mode = True\n",
    "        else:\n",
    "            # í•™ìŠµë•Œë§Œ ì“°ì´ëŠ” Dropout, Batch Mormalizationì„ ë¯¸ì‚¬ìš©\n",
    "            net.eval()\n",
    "            grad_mode = False\n",
    "        \n",
    "        with torch.set_grad_enabled(grad_mode):\n",
    "            result = net(data)\n",
    "             \n",
    "            # Feed Forward\n",
    "            _, out = torch.max(result, 1) # resultì—ì„œ ìµœëŒ€ í™•ë¥ ê°’ì„ ê¸°ì¤€ìœ¼ë¡œ ì˜ˆì¸¡ class ë„ì¶œ\n",
    "        \n",
    "            # 2. Loss ê³„ì‚°\n",
    "            loss = loss_fn(result, label) # GT ì™€ Label ë¹„êµí•˜ì—¬ Loss ì‚°ì •\n",
    "            iter_loss.append(loss.item()) # í•™ìŠµ ì¶”ì´ë¥¼ ìœ„í•˜ì—¬ Lossë¥¼ ê¸°ë¡\n",
    "\n",
    "            # 3. ì—­ì „íŒŒ í•™ìŠµ í›„ Gradient Descent\n",
    "            if mode == 'train':\n",
    "                optim.zero_grad() # ë¯¸ë¶„ì„ í†µí•´ ì–»ì€ ê¸°ìš¸ê¸°ë¥´ ì´ˆê¸°í™” for ë‹¤ìŒ epoch\n",
    "                loss.backward() # ì—­ì „íŒŒ í•™ìŠµ\n",
    "                optim.step() # Gradient Descent ìˆ˜í–‰\n",
    "                last_grad_performed = True # forë¬¸ ë‚˜ê°€ë©´ epoch ì¹´ìš´í„° += 1\n",
    "\n",
    "            # 4. ì •í™•ë„ ê³„ì‚°\n",
    "            acc_partial = (out == label).float().sum() # GT == Label ì¸ ê°œìˆ˜\n",
    "            acc_partial = acc_partial / len(label) # ( TP / (TP + TN)) í•´ì„œ ì •í™•ë„ ì‚°ì¶œ\n",
    "            iter_acc.append(acc_partial.item()) # í•™ìŠµ ì¶”ì´ë¥¼ ìœ„í•˜ì—¬ Acc. ê¸°ë¡\n",
    "    \n",
    "    ### ì´ë²ˆì— ìƒˆë¡œ ë°°ìš°ëŠ” scheduler\n",
    "    scheduler.step() # Learning Rate ìŠ¤ì¼€ì¤„ëŸ¬ ì‹¤í–‰\n",
    "\n",
    "    # ì—­ì „íŒŒ í•™ìŠµ í›„ Epoch ì¹´ìš´í„° += 1\n",
    "    if last_grad_performed:\n",
    "        epoch_cnt += 1\n",
    "    \n",
    "    clear_memory()\n",
    "    \n",
    "    # lossì™€ accì˜ í‰ê· ê°’ for í•™ìŠµì¶”ì´ ê·¸ë˜í”„\n",
    "    return np.average(iter_loss), np.average(iter_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c162e6c8",
   "metadata": {},
   "source": [
    "### ëª¨ë¸ ì„ ì–¸ê³¼ êµ¬ì¡° í™•ì¸(ResNet 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c428fbf0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seed() # ì‹œë“œ ê³ ì •\n",
    "# Training Initialization\n",
    "from torchvision import models\n",
    "model_resnet = models.resnet18(pretrained = True)\n",
    "\n",
    "# ë§ˆì§€ë§‰ fully connected layerì„ ë°”ê¿”ì£¼ëŠ” ì‘ì—…\n",
    "num_ftrs = model_resnet.fc.in_features\n",
    "model_resnet.fc = nn.Linear(num_ftrs, 2)\n",
    "net = model_resnet.to(device)\n",
    "\n",
    "# Model structure check\n",
    "Summary(model_resnet.to(device), (3, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cdd1f6",
   "metadata": {},
   "source": [
    "### ëª¨ë¸ í•™ìŠµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b156381",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed() # ì‹œë“œ ê³ ì •\n",
    "maximum_epoch = 10\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optim = Adam(net.parameters(), lr=0.001)\n",
    "from torch.optim import lr_scheduler\n",
    "lr_scheduler = lr_scheduler.StepLR(optim, step_size = 4, gamma = 0.5)\n",
    "\n",
    "init_epoch()\n",
    "init_log()\n",
    "\n",
    "# Training Iteration\n",
    "while epoch_not_finished():\n",
    "    start_time = time.time()\n",
    "    tloss, tacc = run_resnet(net, dataloader_train, loss_fn, optim, lr_scheduler, mode = 'train')\n",
    "    end_time = time.time()\n",
    "    time_taken = end_time - start_time\n",
    "    record_train_log(tloss, tacc, time_taken)\n",
    "    with torch.no_grad():\n",
    "        vloss, vacc = run_resnet(net, dataloader_val, loss_fn, optim, lr_scheduler, mode = 'val')\n",
    "        record_valid_log(vloss, vacc)\n",
    "    print_log()\n",
    "\n",
    "print('\\n Training completed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e156d0",
   "metadata": {},
   "source": [
    "## 3.2.3 ëª¨ë¸  í‰ê°€\n",
    " - test ë°ì´í„°ì…‹ìœ¼ë¡œ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•œë‹¤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca8dcbf",
   "metadata": {},
   "source": [
    "### Test ë°ì´í„°ì…‹ ì¶œë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1617f2c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "main_path = '{}/test'.format(data_dir)\n",
    "folder_list = os.listdir(main_path)\n",
    "\n",
    "img_list_show = []\n",
    "for folder in folder_list:\n",
    "    img_path = '{}/{}'.format(main_path, folder)\n",
    "    img_list = os.listdir(img_path)\n",
    "    for img_name in img_list: \n",
    "        img_name_path = '{}/{}'.format(img_path, img_name)\n",
    "        img = cv2.imread(img_name_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        img_list_show.append(img)\n",
    "        plt.imshow(img)\n",
    "        plt.title(folder)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b71bff4",
   "metadata": {},
   "source": [
    "### Test ë°ì´í„°ì…‹ì„ Data Loaderì— ì¶”ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892bfb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data_transforms_test = transforms.Compose([Resize(256), ToTensor(), Normalize(mean, std)])\n",
    "# inport data\n",
    "test_data = datasets.ImageFolder(os.path.join(data_dir, 'test'), data_transforms_test)\n",
    "dataloader_test = torch.utils.data.DataLoader(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6a3bf7",
   "metadata": {},
   "source": [
    "### Test ë°ì´í„°ì…‹ìœ¼ë¡œ ì •í™•ë„ í‰ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04da17fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(img_path_list)\n",
    "net.eval()\n",
    "cls = ['ì›ìˆ­ì´', 'ì‚¬ëŒ']\n",
    "cls_english = ['man', 'monkey']\n",
    "cnt = 0\n",
    "true_cnt, false_cnt = 0, 0\n",
    "for inputs, labels in dataloader_test:\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    labels = labels[0].item()\n",
    "\n",
    "    outputs = net(inputs)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    preds = preds[0].item()\n",
    "    \n",
    "    if labels != preds:\n",
    "        print('Image {:3}: {} -> {}   <-- í‹€ë¦¼'.format(cnt, cls[labels], cls[preds]))\n",
    "        false_cnt += 1\n",
    "    else:\n",
    "        print('Image {:3}: {} -> {}'.format(cnt, cls[labels], cls[preds]))\n",
    "        true_cnt += 1\n",
    "        \n",
    "    plt.title('Ground Truth: {} | Predict: {}'.format(cls_english[labels], cls_english[preds]))    \n",
    "    plt.imshow(img_list_show[cnt])\n",
    "    plt.show()\n",
    "    print('')\n",
    "    cnt += 1\n",
    "        \n",
    "acc = true_cnt / (true_cnt + false_cnt)\n",
    "acc = round(acc, 3)\n",
    "print('-----')\n",
    "print('ë§ì€ ê°œìˆ˜: {}ê°œ'.format(true_cnt))\n",
    "print('í‹€ë¦° ê°œìˆ˜: {}ê°œ'.format(false_cnt))\n",
    "print('\\nëª¨ë¸ì˜ Acc.: {}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c26dc01",
   "metadata": {},
   "source": [
    "## Challenge\n",
    " - ì›ìˆ­ì´ë¡œ ë³€ì¥í•œ ì‚¬ëŒ í˜¹ì€ ì‚¬ëŒìœ¼ë¡œ ë³€ì¥í•œ ì›ìˆ­ì´ë¥¼ ëª¨ë¸ë¡œ ì˜ˆì¸¡í•´ ë³¸ë‹¤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d6073f",
   "metadata": {},
   "source": [
    "### Test ë°ì´í„° ë¡œë”ì— ì—…ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17515fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform \n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "data_transforms_test = transforms.Compose([ToTensor(), Resize((244, 244)), Normalize(mean, std)])\n",
    "\n",
    "# ë°ì´í„° ì½ê¸°\n",
    "challenge_data = datasets.ImageFolder(os.path.join('./data_day3/challenge'), data_transforms_test)\n",
    "dataloader_test = torch.utils.data.DataLoader(challenge_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e925b7",
   "metadata": {},
   "source": [
    "### Test ë°ì´í„° ì¶œë ¥ì„ ìœ„í•˜ì—¬ cv2.imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73533cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = []\n",
    "main_path = 'data_day3/challenge/test'\n",
    "img_name_list = os.listdir(main_path)\n",
    "for img_name in img_name_list: \n",
    "    img_name_path = '{}/{}'.format(main_path, img_name)\n",
    "    img = cv2.imread(img_name_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    img_list.append(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b3cb0b",
   "metadata": {},
   "source": [
    "### Challenge ì´ë¯¸ì§€ ë¶„ë¥˜ ê²°ê³¼ - ResNet 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279224b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net.eval()\n",
    "cnt = 0\n",
    "cls = ['man', 'monkey']\n",
    "for inputs, labels in dataloader_test:\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    labels = labels[0].item()\n",
    "    \n",
    "    outputs = net(inputs)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    preds = preds[0].item()\n",
    "    \n",
    "    plt.imshow(img_list[cnt])\n",
    "    plt.title(cls[preds])\n",
    "    plt.show()\n",
    "    cnt += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldl",
   "language": "python",
   "name": "mldl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
