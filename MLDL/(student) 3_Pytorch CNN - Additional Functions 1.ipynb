{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9a48bc1",
   "metadata": {},
   "source": [
    "# 학습 내용\n",
    " - 3.1 Pytorch CIFAR10 - CNN(새로운 데이터셋인 CIFAR-10과 데이터 증강(Data Augmentation)에 대하여 배운다\n",
    " - 3.2 Fine Tuning with Custom Dataset(사람과 원숭이 분류 모델 학습시키기)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d16585e",
   "metadata": {},
   "source": [
    "# 3.1 Pytorch CIFAR-10 - CNN\n",
    " - CNN을 이용하여 새로운 데이터셋인 CIFAR-10을 분류하는 모델을 만들어본다\n",
    " - 데이터 증강(Data Augmentation) 기법을 이용해본다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e81132",
   "metadata": {},
   "source": [
    "## 3.1.1 PyTorch GPU 구동 가능 여부 확인하기\n",
    "- Pytorch를 GPU로 구동할수 있는 조건인지를 확인한다\n",
    "- 결과가 CPU로 나오면, 가상환경을 지우고 다시 깔아야 한다 (Pytorch, Keras 가상환경 만드는법.pptx 참조)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e2ccf6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 사용 불가능 상태\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available() == True:\n",
    "    device = 'cuda:0'\n",
    "    print('현재 가상환경 GPU 사용 가능상태')\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print('GPU 사용 불가능 상태')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ab152f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 교육 환경에서의 시드 고정\n",
    "def seed(seed = 1234):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed() # 시드 고정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e9223b",
   "metadata": {},
   "source": [
    "## 3.1.2 하이퍼 파라미터 설정\n",
    " - 모델 구동에 필요한 하이퍼 파라미터들을 설정한다\n",
    " - 하이퍼 파라미터 설정값에 따라서 모델의 구동 속도, 정확도, 학습 속도가 달라진다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03e90cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "maximum_epoch = 15\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e9b3bd",
   "metadata": {},
   "source": [
    "## 3.1.3 데이터 로드 & 전처리\n",
    " - CIFAR-10 데이터를 다운로드 받는다\n",
    " - Train, Validation, Test 데이터를 분할해준다\n",
    " - 실습 시간을 고려하여 전체 데이터의 절반만 학습하는데 사용하도록 한다\n",
    " - 이미지를 56 * 56으로 Resize시킨다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2730af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed() # 시드 고정\n",
    "# Load dataset into python variable\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToTensor, Resize, Normalize, RandomHorizontalFlip, RandomCrop\n",
    "import numpy as np\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "input_transform = transforms.Compose([ToTensor(), Resize(56), RandomCrop(56, padding = 6), \n",
    "                                      RandomHorizontalFlip(), Normalize(mean, std)])\n",
    "\n",
    "test_transform = transforms.Compose([ToTensor(), Resize(56), Normalize(mean, std)])\n",
    "\n",
    "transform_for_show = transforms.Compose([ToTensor(), Resize(512)])\n",
    "\n",
    "# 코딩타임(CIFAR10 데이터셋 다운로드) - 1분\n",
    "\n",
    "\n",
    "##########\n",
    "\n",
    "from torch.utils.data import random_split\n",
    "train_data, valid_data, _ = random_split(train_data, [20000, 3000, 27000])\n",
    "test_data = CIFAR10(\"./\", train=False, transform=test_transform, download=True)\n",
    "\n",
    "show_data = CIFAR10(\"./\", train=True, transform=transform_for_show, download=True)\n",
    "\n",
    "# Check the data\n",
    "print('Train 길이: {}'.format(len(train_data)))\n",
    "print('Valid 길이: {}'.format(len(valid_data)))\n",
    "print('Test  길이: {}'.format(len(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c38236",
   "metadata": {},
   "source": [
    "- Train / Validation / Test 데이터가 제대로 나뉘었는지 길이를 확인\n",
    "- 데이터를 시각화하여 확인한다\n",
    "- 비행기, 자동차, 새, 고양이, 사슴, 개, 개구리, 말, 배, 트럭 총 10가지 class로 이루어진 데이터셋이다\n",
    "- 각 데이터마다 라벨이 존재한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef95ec5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('모든 Class 출력: {}\\n'.format(test_data.classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f8326d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 모든 Class에 해당하는 사진 확인\n",
    "seed() # 시드 고정\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "cnt = 0\n",
    "for img, label in show_data:\n",
    "    if cnt == 10:\n",
    "        break\n",
    "    if label == cnt:\n",
    "        cnt += 1\n",
    "        img = torchvision.utils.make_grid(img)\n",
    "        npimg = img.numpy()\n",
    "        plt.title('Label: {}'.format(test_data.classes[label]))\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e25751",
   "metadata": {},
   "source": [
    "### 데이터 로더 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a3ce46",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed() # 시드 고정\n",
    "# Create data loader\n",
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, pin_memory=True, drop_last=True)\n",
    "valid_loader = DataLoader(valid_data, batch_size=batch_size, pin_memory=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d6ef9f",
   "metadata": {},
   "source": [
    "## 3.1.4 학습에 필요한 기능 제작\n",
    "- 모델 학습에 필요한 기능들(학습, 시각화, 결과 분석)등을 위해 필요한 기능들을 선언한다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54c8af9",
   "metadata": {},
   "source": [
    "## 3.1.5 모델 선언후 학습 - CNN with Data Augmentation(VGG11 따라하기)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c62261",
   "metadata": {},
   "source": [
    "### 모델 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2758ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Model\n",
    "from torch.optim import Adam\n",
    "def init_model():\n",
    "    global net, loss_fn, optim\n",
    "    net = CNN_Model().to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optim = Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "class CNN_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_Model, self).__init__()\n",
    "        \n",
    "        # 코딩타임\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        ##########\n",
    "    \n",
    "    def forward(self, data):\n",
    "        conv_out = self.convolution_part(data)\n",
    "        avg_out = self.channelavg_part(conv_out)\n",
    "        avg_out_flatten = avg_out.reshape(avg_out.size(0), -1)\n",
    "        classifier_out = self.classifier_part(avg_out_flatten)\n",
    "        return classifier_out, conv_out\n",
    "\n",
    "from torchsummary import summary as Summary\n",
    "# Model structure check\n",
    "Summary(CNN_Model().to(device), (3, 56, 56))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da77e728",
   "metadata": {},
   "source": [
    "## 학습에 사용되는 함수\n",
    " - 초기화\n",
    " - 모델 구동\n",
    " - 학습 추이"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995fded9",
   "metadata": {},
   "source": [
    "### 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00409750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 초기화\n",
    "from torch.optim import Adam\n",
    "def init_model():\n",
    "    plt.rc('font', size = 10)\n",
    "    global net, loss_fn, optim\n",
    "    net = CNN_Model().to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optim = Adam(net.parameters(), lr=learning_rate)\n",
    "    \n",
    "# epoch 카운터 초기화\n",
    "def init_epoch():\n",
    "    global epoch_cnt\n",
    "    epoch_cnt = 0\n",
    "\n",
    "def init_log():\n",
    "    plt.rc('font', size = 10)\n",
    "    # 모든 Log를 초기화\n",
    "    global log_stack, iter_log, tloss_log, tacc_log, vloss_log, vacc_log, time_log\n",
    "    iter_log, tloss_log, tacc_log, vloss_log, vacc_log = [], [], [], [], []\n",
    "    time_log, log_stack = [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2ad05a",
   "metadata": {},
   "source": [
    "### 모델 구동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ef4028",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from torch.cuda import memory_allocated, empty_cache\n",
    "def clear_memory():\n",
    "    if device != 'cpu':\n",
    "        empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "# 학습 알고리즘\n",
    "import numpy as np\n",
    "def epoch(data_loader, mode = 'train'):\n",
    "    global epoch_cnt\n",
    "    \n",
    "    # 사용되는 변수 초기화\n",
    "    iter_loss, iter_acc, last_grad_performed  = [], [], False\n",
    "    \n",
    "    # 1 iteration 학습 알고리즘(for문을 나오면 1 epoch 완료)\n",
    "    for _data, _label in data_loader:\n",
    "        data, label = _data.to(device), _label.to(device)\n",
    "        \n",
    "        # 1. Feed-forward\n",
    "        if mode == 'train':\n",
    "            net.train()\n",
    "        else:\n",
    "            # 학습때만 쓰이는 Dropout, Batch Mormalization을 미사용\n",
    "            net.eval()\n",
    "\n",
    "        result, _ = net(data) # 1 Batch에 대한 결과가 모든 Class에 대한 확률값으로\n",
    "        _, out = torch.max(result, 1) # result에서 최대 확률값을 기준으로 예측 class 도출\n",
    "        \n",
    "        # 2. Loss 계산\n",
    "        loss = loss_fn(result, label) # GT 와 Label 비교하여 Loss 산정\n",
    "        iter_loss.append(loss.item()) # 학습 추이를 위하여 Loss를 기록\n",
    "        \n",
    "        # 3. 역전파 학습 후 Gradient Descent\n",
    "        if mode == 'train':\n",
    "            optim.zero_grad() # 미분을 통해 얻은 기울기 초기화 for 다음 epoch\n",
    "            loss.backward() # 역전파 학습\n",
    "            optim.step() # Gradient Descent 수행\n",
    "            last_grad_performed = True # for문 나가면 epoch 카운터 += 1\n",
    "            \n",
    "        # 4. 정확도 계산\n",
    "        acc_partial = (out == label).float().sum() # GT == Label 인 개수\n",
    "        acc_partial = acc_partial / len(label) # ( TP / (TP + FP)) 해서 정확도 산출\n",
    "        iter_acc.append(acc_partial.item()) # 학습 추이를 위하여 Acc. 기록\n",
    "\n",
    "    # 역전파 학습 후 Epoch 카운터 += 1\n",
    "    if last_grad_performed:\n",
    "        epoch_cnt += 1\n",
    "    \n",
    "    clear_memory()\n",
    "    \n",
    "    # loss와 acc의 평균값 for 학습추이 그래프\n",
    "    return np.average(iter_loss), np.average(iter_acc)\n",
    "\n",
    "def epoch_not_finished():\n",
    "    # 에폭이 끝남을 알림\n",
    "    return epoch_cnt < maximum_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f172a7",
   "metadata": {},
   "source": [
    "### 학습 추이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bc29fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_train_log(_tloss, _tacc, _time):\n",
    "    # Train Log 기록용\n",
    "    time_log.append(_time)\n",
    "    tloss_log.append(_tloss)\n",
    "    tacc_log.append(_tacc)\n",
    "    iter_log.append(epoch_cnt)\n",
    "    \n",
    "def record_valid_log(_vloss, _vacc):\n",
    "    # Validation Log 기록용\n",
    "    vloss_log.append(_vloss)\n",
    "    vacc_log.append(_vacc)\n",
    "\n",
    "def last(log_list):\n",
    "    # 리스트 안의 마지막 숫자를 반환(print_log 함수에서 사용)\n",
    "    if len(log_list) > 0:\n",
    "        return log_list[len(log_list) - 1]\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "from IPython.display import clear_output\n",
    "def print_log():\n",
    "    # 학습 추이 출력\n",
    "\n",
    "    # 소숫점 3자리 수까지 조절\n",
    "    train_loss = round(float(last(tloss_log)), 3)\n",
    "    train_acc = round(float(last(tacc_log)), 3)\n",
    "    val_loss = round(float(last(vloss_log)), 3)\n",
    "    val_acc = round(float(last(vacc_log)), 3)\n",
    "    time_spent = round(float(last(time_log)), 3)\n",
    "    \n",
    "    log_str = 'Epoch: {:3} | T_Loss {:5} | T_acc {:5} | V_Loss {:5} | V_acc. {:5} | \\\n",
    "🕒 {:5}'.format(last(iter_log), train_loss, train_acc, val_loss, val_acc, time_spent)\n",
    "    \n",
    "    log_stack.append(log_str) # 프린트 준비\n",
    "    \n",
    "    # 학습 추이 그래프 출력\n",
    "    hist_fig, loss_axis = plt.subplots(figsize=(10, 3), dpi=99) # 그래프 사이즈 설정\n",
    "    hist_fig.patch.set_facecolor('white') # 그래프 배경색 설정\n",
    "    \n",
    "    # Loss Line 구성\n",
    "    loss_t_line = plt.plot(iter_log, tloss_log, label='Train Loss', color='red', marker='o')\n",
    "    loss_v_line = plt.plot(iter_log, vloss_log, label='Valid Loss', color='blue', marker='s')\n",
    "    loss_axis.set_xlabel('epoch')\n",
    "    loss_axis.set_ylabel('loss')\n",
    "    \n",
    "    # Acc. Line 구성\n",
    "    acc_axis = loss_axis.twinx()\n",
    "    acc_t_line = acc_axis.plot(iter_log, tacc_log, label='Train Acc.', color='red', marker='+')\n",
    "    acc_v_line = acc_axis.plot(iter_log, vacc_log, label='Valid Acc.', color='blue', marker='x')\n",
    "    acc_axis.set_ylabel('accuracy')\n",
    "    \n",
    "    # 그래프 출력\n",
    "    hist_lines = loss_t_line + loss_v_line + acc_t_line + acc_v_line # 위에서 선언한 plt정보들 통합\n",
    "    loss_axis.legend(hist_lines, [l.get_label() for l in hist_lines], loc = 'upper right') # 순서대로 그려주기\n",
    "    loss_axis.grid() # 격자 설정\n",
    "    plt.title('Learning history until epoch {}'.format(last(iter_log)))\n",
    "    plt.draw()\n",
    "    \n",
    "    # 텍스트 로그 출력\n",
    "    clear_output(wait=True)\n",
    "    plt.show()\n",
    "    for idx in reversed(range(len(log_stack))): # 반대로 sort 시켜서 출력\n",
    "        print(log_stack[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1430e46a",
   "metadata": {},
   "source": [
    "### 모델 학습 후 모델의 정확도 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adff80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed() # 시드 고정\n",
    "# Training Initialization\n",
    "init_model()\n",
    "init_epoch()\n",
    "init_log()\n",
    "\n",
    "# Training Iteration\n",
    "import time\n",
    "while epoch_not_finished():\n",
    "    start_time = time.time()\n",
    "    tloss, tacc = epoch(train_loader, mode = 'train')\n",
    "    end_time = time.time()\n",
    "    time_taken = end_time - start_time\n",
    "    record_train_log(tloss, tacc, time_taken)\n",
    "    with torch.no_grad():\n",
    "        vloss, vacc = epoch(valid_loader, mode = 'val')\n",
    "        record_valid_log(vloss, vacc)\n",
    "    print_log()\n",
    "\n",
    "print('\\n Training completed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35cccfe",
   "metadata": {},
   "source": [
    "### 모델의 정확도 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e61c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확도 검증\n",
    "with torch.no_grad():\n",
    "    test_loss, test_acc = epoch(test_loader, mode = 'test')\n",
    "    test_acc = round(test_acc, 4)\n",
    "    test_loss = round(test_loss, 4)\n",
    "    print('Test Acc.: {}'.format(test_acc))\n",
    "    print('Test Loss: {}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f180d6ea",
   "metadata": {},
   "source": [
    "# ============================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5891a85a",
   "metadata": {},
   "source": [
    " - 3.1 CNN - CIFAR 10\n",
    " - 3.2 Transfer Learning   <---\n",
    " - 3.3 GAN with MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb8a8d2",
   "metadata": {},
   "source": [
    "# 3.2 Transfer Learning with Custom Dataset\n",
    " - 커스템 데이터셋을 이용하여 Fine tuning을 익힌다(ResNet18)\n",
    " - ResNet18에 사람과 원숭이를 학습하여 분류 모델을 제작해본다\n",
    " - Test Dataset을 직접 구하여, 모델이 효과적으로 사람과 원숭이를 분류하는지 실험해본다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7286c854",
   "metadata": {},
   "source": [
    "## 3.2.1 Train 데이터 로드 & 전처리\n",
    " - 학습할 커스텀 데이터셋의 형식을 지정해준다\n",
    " - 커스템 데이터셋 이미지들의 폴더 경로를 지정한다\n",
    " - 이미지의 사이즈를 224 * 224로 리사이즈 해준다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec9eb80",
   "metadata": {},
   "source": [
    "### Split Folder로 Train 데이터 자동 분할하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531f3d99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import splitfolders\n",
    "input_folder = './data_day3/dataset_ManAndMonkey_small'\n",
    "output = './data_day3/split_folders_small'\n",
    "\n",
    "# 코딩타임(split folders를 사용하여 데이터 분할하기)\n",
    "\n",
    "\n",
    "\n",
    "##########"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce02724",
   "metadata": {},
   "source": [
    "### Train 데이터 Class마다 5장씩 출력해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6b07cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "data_dir = './data_day3/split_folders_small'\n",
    "train_dir = '{}/train'.format(data_dir)\n",
    "train_folder_list = os.listdir(train_dir)\n",
    " \n",
    "all_imgs = []\n",
    "cnt, cnt_goal = 0, 5\n",
    "num_man, num_monkey = 0, 0\n",
    "\n",
    "import cv2\n",
    "for folder in train_folder_list:\n",
    "    img_name_list = os.listdir('{}/{}'.format(train_dir, folder))\n",
    "    cnt = 0\n",
    "    if 'man' in folder:\n",
    "        num_man = len(img_name_list)\n",
    "    elif 'monkey' in folder:\n",
    "        num_monkey = len(img_name_list)\n",
    "    for img_name in img_name_list:\n",
    "        if cnt_goal == cnt:\n",
    "            break\n",
    "        img_dir = '{}/{}/{}'.format(train_dir, folder, img_name)\n",
    "        img = cv2.imread(img_dir)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        plt.imshow(img)\n",
    "        plt.title('Train: {}'.format(folder))\n",
    "        plt.show()\n",
    "        cnt += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3dd530",
   "metadata": {},
   "source": [
    "### Train 데이터의 개수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5437862",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train 사람사진: {}개'.format(num_man))\n",
    "print('Train 원숭이 사진: {}개'.format(num_monkey))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befb6cf0",
   "metadata": {},
   "source": [
    "### Train 데이터 transforms.Compose로 전처리 옵션 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3eb88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "data_transforms_train = transforms.Compose([ToTensor(), Resize((224,224)), RandomHorizontalFlip(), Normalize(mean, std)])\n",
    "data_transforms_val = transforms.Compose([ToTensor(), Resize((224,224)), Normalize(mean, std)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1849b6a2",
   "metadata": {},
   "source": [
    "### Train 데이터 로더에 사진 업로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9505bbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inport data\n",
    "from torchvision import datasets\n",
    "train_data = datasets.ImageFolder(os.path.join(data_dir, 'train'), data_transforms_train)\n",
    "val_data = datasets.ImageFolder(os.path.join(data_dir, 'val'), data_transforms_val)\n",
    "\n",
    "dataloader_train = torch.utils.data.DataLoader(train_data, batch_size = 10, shuffle = True)\n",
    "dataloader_val = torch.utils.data.DataLoader(val_data, batch_size = len(val_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b032f0f",
   "metadata": {},
   "source": [
    "## 3.2.2 모델 선언후 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578c3694",
   "metadata": {},
   "source": [
    "### 모델 학습 알고리즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a7e887",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_resnet(net, data_loader, loss_fn, optim, scheduler, mode = 'train'):\n",
    "    global epoch_cnt\n",
    "    iter_loss, iter_acc, last_grad_performed = [], [], False\n",
    "\n",
    "    for _data, _label in data_loader:\n",
    "        data, label = _data.to(device), _label.to(device)\n",
    "        \n",
    "        # 1. Feed-forward\n",
    "        if mode == 'train':\n",
    "            net.train()\n",
    "            grad_mode = True\n",
    "        else:\n",
    "            # 학습때만 쓰이는 Dropout, Batch Mormalization을 미사용\n",
    "            net.eval()\n",
    "            grad_mode = False\n",
    "        \n",
    "        with torch.set_grad_enabled(grad_mode):\n",
    "            result = net(data)\n",
    "             \n",
    "            # Feed Forward\n",
    "            _, out = torch.max(result, 1) # result에서 최대 확률값을 기준으로 예측 class 도출\n",
    "        \n",
    "            # 2. Loss 계산\n",
    "            loss = loss_fn(result, label) # GT 와 Label 비교하여 Loss 산정\n",
    "            iter_loss.append(loss.item()) # 학습 추이를 위하여 Loss를 기록\n",
    "\n",
    "            # 3. 역전파 학습 후 Gradient Descent\n",
    "            if mode == 'train':\n",
    "                optim.zero_grad() # 미분을 통해 얻은 기울기르 초기화 for 다음 epoch\n",
    "                loss.backward() # 역전파 학습\n",
    "                optim.step() # Gradient Descent 수행\n",
    "                last_grad_performed = True # for문 나가면 epoch 카운터 += 1\n",
    "\n",
    "            # 4. 정확도 계산\n",
    "            acc_partial = (out == label).float().sum() # GT == Label 인 개수\n",
    "            acc_partial = acc_partial / len(label) # ( TP / (TP + TN)) 해서 정확도 산출\n",
    "            iter_acc.append(acc_partial.item()) # 학습 추이를 위하여 Acc. 기록\n",
    "    \n",
    "    ### 이번에 새로 배우는 scheduler\n",
    "    scheduler.step() # Learning Rate 스케줄러 실행\n",
    "\n",
    "    # 역전파 학습 후 Epoch 카운터 += 1\n",
    "    if last_grad_performed:\n",
    "        epoch_cnt += 1\n",
    "    \n",
    "    clear_memory()\n",
    "    \n",
    "    # loss와 acc의 평균값 for 학습추이 그래프\n",
    "    return np.average(iter_loss), np.average(iter_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c162e6c8",
   "metadata": {},
   "source": [
    "### 모델 선언과 구조 확인(ResNet 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c428fbf0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seed() # 시드 고정\n",
    "# Training Initialization\n",
    "from torchvision import models\n",
    "model_resnet = models.resnet18(pretrained = True)\n",
    "\n",
    "# 마지막 fully connected layer을 바꿔주는 작업\n",
    "num_ftrs = model_resnet.fc.in_features\n",
    "model_resnet.fc = nn.Linear(num_ftrs, 2)\n",
    "net = model_resnet.to(device)\n",
    "\n",
    "# Model structure check\n",
    "Summary(model_resnet.to(device), (3, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cdd1f6",
   "metadata": {},
   "source": [
    "### 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b156381",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed() # 시드 고정\n",
    "maximum_epoch = 10\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optim = Adam(net.parameters(), lr=0.001)\n",
    "from torch.optim import lr_scheduler\n",
    "lr_scheduler = lr_scheduler.StepLR(optim, step_size = 4, gamma = 0.5)\n",
    "\n",
    "init_epoch()\n",
    "init_log()\n",
    "\n",
    "# Training Iteration\n",
    "while epoch_not_finished():\n",
    "    start_time = time.time()\n",
    "    tloss, tacc = run_resnet(net, dataloader_train, loss_fn, optim, lr_scheduler, mode = 'train')\n",
    "    end_time = time.time()\n",
    "    time_taken = end_time - start_time\n",
    "    record_train_log(tloss, tacc, time_taken)\n",
    "    with torch.no_grad():\n",
    "        vloss, vacc = run_resnet(net, dataloader_val, loss_fn, optim, lr_scheduler, mode = 'val')\n",
    "        record_valid_log(vloss, vacc)\n",
    "    print_log()\n",
    "\n",
    "print('\\n Training completed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e156d0",
   "metadata": {},
   "source": [
    "## 3.2.3 모델  평가\n",
    " - test 데이터셋으로 모델의 성능을 평가한다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca8dcbf",
   "metadata": {},
   "source": [
    "### Test 데이터셋 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1617f2c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "main_path = '{}/test'.format(data_dir)\n",
    "folder_list = os.listdir(main_path)\n",
    "\n",
    "img_list_show = []\n",
    "for folder in folder_list:\n",
    "    img_path = '{}/{}'.format(main_path, folder)\n",
    "    img_list = os.listdir(img_path)\n",
    "    for img_name in img_list: \n",
    "        img_name_path = '{}/{}'.format(img_path, img_name)\n",
    "        img = cv2.imread(img_name_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        img_list_show.append(img)\n",
    "        plt.imshow(img)\n",
    "        plt.title(folder)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b71bff4",
   "metadata": {},
   "source": [
    "### Test 데이터셋을 Data Loader에 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892bfb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data_transforms_test = transforms.Compose([Resize(256), ToTensor(), Normalize(mean, std)])\n",
    "# inport data\n",
    "test_data = datasets.ImageFolder(os.path.join(data_dir, 'test'), data_transforms_test)\n",
    "dataloader_test = torch.utils.data.DataLoader(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6a3bf7",
   "metadata": {},
   "source": [
    "### Test 데이터셋으로 정확도 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04da17fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(img_path_list)\n",
    "net.eval()\n",
    "cls = ['원숭이', '사람']\n",
    "cls_english = ['man', 'monkey']\n",
    "cnt = 0\n",
    "true_cnt, false_cnt = 0, 0\n",
    "for inputs, labels in dataloader_test:\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    labels = labels[0].item()\n",
    "\n",
    "    outputs = net(inputs)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    preds = preds[0].item()\n",
    "    \n",
    "    if labels != preds:\n",
    "        print('Image {:3}: {} -> {}   <-- 틀림'.format(cnt, cls[labels], cls[preds]))\n",
    "        false_cnt += 1\n",
    "    else:\n",
    "        print('Image {:3}: {} -> {}'.format(cnt, cls[labels], cls[preds]))\n",
    "        true_cnt += 1\n",
    "        \n",
    "    plt.title('Ground Truth: {} | Predict: {}'.format(cls_english[labels], cls_english[preds]))    \n",
    "    plt.imshow(img_list_show[cnt])\n",
    "    plt.show()\n",
    "    print('')\n",
    "    cnt += 1\n",
    "        \n",
    "acc = true_cnt / (true_cnt + false_cnt)\n",
    "acc = round(acc, 3)\n",
    "print('-----')\n",
    "print('맞은 개수: {}개'.format(true_cnt))\n",
    "print('틀린 개수: {}개'.format(false_cnt))\n",
    "print('\\n모델의 Acc.: {}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c26dc01",
   "metadata": {},
   "source": [
    "## Challenge\n",
    " - 원숭이로 변장한 사람 혹은 사람으로 변장한 원숭이를 모델로 예측해 본다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d6073f",
   "metadata": {},
   "source": [
    "### Test 데이터 로더에 업로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17515fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform \n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "data_transforms_test = transforms.Compose([ToTensor(), Resize((244, 244)), Normalize(mean, std)])\n",
    "\n",
    "# 데이터 읽기\n",
    "challenge_data = datasets.ImageFolder(os.path.join('./data_day3/challenge'), data_transforms_test)\n",
    "dataloader_test = torch.utils.data.DataLoader(challenge_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e925b7",
   "metadata": {},
   "source": [
    "### Test 데이터 출력을 위하여 cv2.imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73533cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = []\n",
    "main_path = 'data_day3/challenge/test'\n",
    "img_name_list = os.listdir(main_path)\n",
    "for img_name in img_name_list: \n",
    "    img_name_path = '{}/{}'.format(main_path, img_name)\n",
    "    img = cv2.imread(img_name_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    img_list.append(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b3cb0b",
   "metadata": {},
   "source": [
    "### Challenge 이미지 분류 결과 - ResNet 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279224b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net.eval()\n",
    "cnt = 0\n",
    "cls = ['man', 'monkey']\n",
    "for inputs, labels in dataloader_test:\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    labels = labels[0].item()\n",
    "    \n",
    "    outputs = net(inputs)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    preds = preds[0].item()\n",
    "    \n",
    "    plt.imshow(img_list[cnt])\n",
    "    plt.title(cls[preds])\n",
    "    plt.show()\n",
    "    cnt += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldl",
   "language": "python",
   "name": "mldl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
